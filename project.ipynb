{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit/Quora scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw #Reddit scraper\n",
    "import re #Regular expressions\n",
    "import random #To select a comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reddit API use your own credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.2.0 of praw is outdated. Version 7.3.0 was released 1 day ago.\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=\"LSZOduypQfuIUw\",\n",
    "    client_secret=\"4-RBX3XtMd52Q3FYRuuXb3I-9IhatQ\",\n",
    "    password=\"H4tutspa44word\",\n",
    "    user_agent=\"Tutorial\",\n",
    "    username=\"Hktuts\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if we're set up correctly (should return our reddit username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hktuts\n"
     ]
    }
   ],
   "source": [
    "print(reddit.user.me())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### URL to the thread we want to scrape comments from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.reddit.com/r/worldnews/comments/mo0vvc/norway_prime_minister_fined_1715_for_breaking/\"\n",
    "submission = reddit.submission(url=url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping reddit comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of comments scraped from thread: 1989\n"
     ]
    }
   ],
   "source": [
    "comments = []\n",
    "\n",
    "submission.comments.replace_more(limit=None)\n",
    "\n",
    "for comment in submission.comments.list():\n",
    "    comments.append(comment.body)\n",
    "\n",
    "print(\"Number of comments scraped from thread: \" + str(len(comments)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Picking a random comment from the first 50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine holding your head of government accountable for their actions. \n",
      "\n",
      "Not in America, thatâ€™s for sure.\n"
     ]
    }
   ],
   "source": [
    "print(comments[(random.randint(1, 50))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quora scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Question': [], 'No. of answers': [],'answers':[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping the question and number of answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-215-1709b9e1a16c>:9: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=chrome_options, executable_path=r'chromedriver.exe')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped question: What is it like to live in Norway?\n",
      "23 Answers in total\n"
     ]
    }
   ],
   "source": [
    "    question_link = 'https://www.quora.com/What-is-it-like-to-live-in-Norway'\n",
    "    \n",
    "    #selenium settings\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\" --window-size=1920x1080\")\n",
    "    \n",
    "    #open instance\n",
    "    driver = webdriver.Chrome(chrome_options=chrome_options, executable_path=r'chromedriver.exe')\n",
    "    driver.get(question_link)\n",
    "    time.sleep(1)\n",
    "    elem = driver.find_element_by_tag_name(\"body\")\n",
    "    \n",
    "    #scrape question Name\n",
    "    qname = driver.find_elements_by_xpath(\"/html/body/div[2]/div[2]/div/div/div/div[4]/div/div/div[1]/div[1]/div/div/span/span/div/div/div/span/span\")\n",
    "    for value in qname:\n",
    "        print(\"Scraped question: \" + value.text)\n",
    "    \n",
    "    #Scrape answer count\n",
    "    count = driver.find_elements_by_xpath(\"/html/body/div[2]/div[2]/div/div/div/div[4]/div/div/div[1]/div[2]/div[2]/div/div/div/div/div\")\n",
    "    for e in count:\n",
    "        print(e.text + \" in total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping answers from a question (work in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-216-2bf8bb0e99be>:1: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=chrome_options, executable_path=r'chromedriver.exe')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Answers: 52\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    driver = webdriver.Chrome(chrome_options=chrome_options, executable_path=r'chromedriver.exe')\n",
    "    \n",
    "    # give the url to scrap\n",
    "    driver.get(question_link)\n",
    "        \n",
    "    # define pause time for browser\n",
    "    SCROLL_PAUSE_TIME = 1\n",
    "\n",
    "\t# get browser source\n",
    "    html_source = driver.page_source\n",
    "    question_count_soup = BeautifulSoup(html_source, 'html.parser')\n",
    "\n",
    "\t# Get scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    answer_set = set()\n",
    "\n",
    "    #infinite while loop, break it when you reach the end of the page or not able to scroll further.\n",
    "    while True:\n",
    "            html_source = \" \"\n",
    "            i = 0\n",
    "\n",
    "\t#try to scroll 20 times in case of slow connection\n",
    "            while i < 20:\n",
    "\n",
    "                   #Scroll down to one page length\n",
    "                   driver.execute_script(\"window.scrollBy(0, 1080);\")\n",
    "\n",
    "\t\t\t\t#  Wait to load page\n",
    "                   time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "\t\t\t\t#  get page height in pixels\n",
    "                   new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "\t\t\t\t#  break this loop when you are able to scroll futher\n",
    "                   if new_height != last_height:\n",
    "                        \n",
    "                        break     \n",
    "                        \n",
    "                   i += 1\n",
    "                   \n",
    "            # get html page source\n",
    "            html_source = driver.page_source\n",
    "            soup = BeautifulSoup(html_source, 'html.parser')\n",
    "\n",
    "            #question_link is the class for questions\n",
    "            answer_texts = soup.find_all('span', attrs={'class' : 'q-box qu-userSelect--text'})\n",
    "            \n",
    "\n",
    "\t\t    # add questions to a set for uniqueness\n",
    "            for answer in answer_texts:\n",
    "                \n",
    "                answer = str(answer).lstrip(\"<div class=\\\"ui_qtext_expanded\\\"><span class=\\\"ui_qtext_rendered_qtext\\\">\").rstrip(\"</span></div>\")\n",
    "                answer_set.add(answer)\n",
    "\n",
    "            # not able to scroll further, break the infinite loop\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "            print('Total Answers: ' + str(len(answer_set)))\n",
    "            break\n",
    "            \n",
    "            #quit browser finally when our scraping is done            \n",
    "    browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f895f3828335fe46f73ce365c88adfdf701549b1031659c6fc3c92d79d692c8b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
