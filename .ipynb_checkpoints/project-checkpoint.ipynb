{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit/Quora scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw #Reddit scraper\n",
    "import re #Regular expressions\n",
    "import random #To select a comment\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reddit API use your own credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=\"LSZOduypQfuIUw\",\n",
    "    client_secret=\"4-RBX3XtMd52Q3FYRuuXb3I-9IhatQ\",\n",
    "    password=\"H4tutspa44word\",\n",
    "    user_agent=\"Tutorial\",\n",
    "    username=\"Hktuts\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if we're set up correctly (should return our reddit username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hktuts\n"
     ]
    }
   ],
   "source": [
    "print(reddit.user.me())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### URL to the thread we want to scrape comments from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.reddit.com/r/worldnews/comments/mo0vvc/norway_prime_minister_fined_1715_for_breaking/\"\n",
    "submission = reddit.submission(url=url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping reddit comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of comments scraped from thread: 1988\n"
     ]
    }
   ],
   "source": [
    "comments = []\n",
    "\n",
    "submission.comments.replace_more(limit=None)\n",
    "\n",
    "for comment in submission.comments.list():\n",
    "    comments.append(comment.body)\n",
    "\n",
    "print(\"Number of comments scraped from thread: \" + str(len(comments)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Picking a random comment from the first 50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One rule for thee another rule for wait a second, what?\n"
     ]
    }
   ],
   "source": [
    "print(comments[(random.randint(1, 50))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quora scraping\n",
    "#### Scraping the question, answers and user-id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "DEBUG = 1\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import ast\n",
    "import csv\n",
    "import json\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import random\n",
    "import argparse\n",
    "import sys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import dateparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to convert answer dates dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertDateFormat(dateText):\n",
    "\ttry:\n",
    "\t\tif (\"Updated\" in dateText):\n",
    "\t\t\tdate = dateText[8:]\n",
    "\t\telse:\n",
    "\t\t\tdate = dateText[9:]\n",
    "\t\tdate = dateparser.parse(dateText).strftime(\"%Y-%m-%d\")\n",
    "\texcept:  # when updated or answered in the same week (ex: Updated Sat)\n",
    "\t\tdate = dateparser.parse(\"7 days ago\").strftime(\"%Y-%m-%d\")\n",
    "\treturn date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to scroll up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrollup_alittle(self,nbtimes):\n",
    "\n",
    "    for iii in range(0,nbtimes):\n",
    "        self.execute_script(\"window.scrollBy(0,-200)\")\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to simulate scrolling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for loading  quora dynamic content\n",
    "def scrolldown(self,type_of_page='users'):\n",
    "    last_height = self.page_source\n",
    "    loop_scroll=True\n",
    "    attempt = 0\n",
    "    # we generate a random waiting time between 2 and 4\n",
    "    waiting_scroll_time=round(random.uniform(2, 4),1)\n",
    "    print('scrolling down to get all answers...')\n",
    "    max_waiting_time=round(random.uniform(5, 7),1)\n",
    "    # we increase waiting time when we look for questions urls\t\n",
    "    if type_of_page=='questions' : max_waiting_time= round(random.uniform(20, 30),1)\n",
    "    # scroll down loop until page not changing\n",
    "    while loop_scroll:\n",
    "        self.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "        if type_of_page=='answers':\n",
    "            scrollup_alittle(self,2)\n",
    "        new_height=self.page_source\n",
    "        if new_height == last_height:\n",
    "            # in case of not change, we increase the waiting time\n",
    "            waiting_scroll_time= max_waiting_time\n",
    "            attempt += 1\n",
    "            if attempt==3:# in the third attempt we end the scrolling\n",
    "                loop_scroll=False\n",
    "            #print('attempt',attempt)\n",
    "        else:\n",
    "            attempt=0\n",
    "            waiting_scroll_time=round(random.uniform(2, 4),1)\n",
    "        last_height=new_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to scrape answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def answers(urls_list,save_path):\n",
    "    \n",
    "    #selenium settings\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\" --window-size=1920x1080\")\n",
    "    \n",
    "    url_index = -1\n",
    "    loop_limit= 1\n",
    "    \n",
    "    driver = webdriver.Chrome(chrome_options=chrome_options, executable_path=r'chromedriver.exe')\n",
    "    # give the url to scrap\n",
    "    driver.get(urls_list[url_index])\n",
    "    \n",
    "    \n",
    "    # output file containing all answers\n",
    "    file_answers = open(Path(save_path) / \"answers.txt\", mode='a') \n",
    "    print('Starting the answers crawling...')\n",
    "    \n",
    "    while True:\n",
    "        url_index += 1\n",
    "        print('--------------------------------------------------')\n",
    "        if url_index >= loop_limit:\n",
    "            print('Crawling completed, answers have been saved to  :  ', save_path)\n",
    "            driver.quit()\n",
    "            file_answers.close()\n",
    "            break\n",
    "        current_line = urls_list[url_index]\n",
    "        print('processing question number  : '+ str(url_index+1))\n",
    "        print(current_line)\n",
    "        if '/unanswered/' in str(current_line):\n",
    "            print('answer is unanswered')\n",
    "            continue\n",
    "        question_id = current_line\n",
    "        # opening Question page\n",
    "        try:\n",
    "            driver.get(current_line)\n",
    "            time.sleep(2)\n",
    "        except Exception as OpenEx:\n",
    "            print('cant open the following question link : ',current_line)\n",
    "            print('Error on line {}'.format(sys.exc_info()[-1].tb_lineno), type(OpenEx).__name__, OpenEx)\n",
    "            print(str(OpenEx))\n",
    "            continue\n",
    "        try:\n",
    "            nb_answers_text = WebDriverWait(driver, 10).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, \"//div[text()[contains(.,'Answer')]]\"))).text\n",
    "            nb_answers=[int(s.strip('+')) for s in nb_answers_text.split() if s.strip('+').isdigit()][0]\n",
    "            print('Question have :', nb_answers_text)\n",
    "            \n",
    "           \n",
    "        except Exception as Openans: \n",
    "            print('cant get answers')\n",
    "            print('Error on line {}'.format(sys.exc_info()[-1].tb_lineno), type(Openans).__name__, Openans)\n",
    "            print(str(Openans))\n",
    "            continue\n",
    "        #nb_answers_text = browser.find_element_by_xpath(\"//div[@class='QuestionPageAnswerHeader']//div[@class='answer_count']\").text\n",
    "       \n",
    "        #-------------------------------------------------------------------------------------\n",
    "        \n",
    "        if nb_answers > 7:\n",
    "            scrolldown(driver,'answers')\n",
    "        continue_reading_buttons = driver.find_elements_by_name(\"ChevronDown\")\n",
    "        time.sleep(1)\n",
    "        for button in continue_reading_buttons:\n",
    "            try:\n",
    "                ActionChains(driver).click(button).perform()\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                print('cant click more')\n",
    "                continue\n",
    "                \n",
    "        print(\"opened a total of \" + str(len(continue_reading_buttons)) + \" question boxes\")\n",
    "        time.sleep(2)\n",
    "        html_source = driver.page_source\n",
    "        soup = BeautifulSoup(html_source,\"html.parser\")\n",
    "        # get the question-id\n",
    "        question_id = current_line.rsplit('/', 1)[-1]\n",
    "        # find title \n",
    "        title = current_line.replace(\"https://www.quora.com/\",\"\")\n",
    "        # find question's topics\n",
    "        questions_topics = soup.findAll(\"div\", {\"class\": \"q-box qu-mr--tiny qu-mb--tiny\"})\n",
    "        questions_topics_text=[]\n",
    "        for topic in questions_topics : questions_topics_text.append(topic.text.rstrip())\n",
    "        # number of answers\n",
    "        # not all answers are saved!\n",
    "        # answers that collapsed, and those written by annonymous users are not saved\n",
    "        try:\n",
    "            split_html = html_source.split('q-box qu-pt--medium')\n",
    "        except Exception as notexist :#mostly because question is deleted by quora\n",
    "            print('question no long exists')\n",
    "            print('Error on line {}'.format(sys.exc_info()[-1].tb_lineno), type(notexist).__name__, notexist)\n",
    "            print(str(notexist))\n",
    "            continue \n",
    "   \n",
    "        # The underneath loop will generate len(split_html)/2 exceptions, cause answers in split_html\n",
    "        # are eitheir in Odd or Pair positions, so ignore printed exceptions.\n",
    "        #print('len split : ',len(split_html))\n",
    "        for i in range(1, len(split_html)):\n",
    "            try:\n",
    "                part = split_html[i]\n",
    "                part_soup = BeautifulSoup(part,\"html.parser\" )\n",
    "                #find users names of answers authors\n",
    "                try:\n",
    "                    authors=part_soup.find(\"a\", href=lambda href: href and \"/profile/\" in href)\n",
    "                    user_id = authors['href'].rsplit('/', 1)[-1]\n",
    "                    #print(user_id)\n",
    "                except Exception as notexist2 :#mostly because question is deleted by quora\n",
    "                    \n",
    "                    #print('author extract pb')\n",
    "                    #print('Error on line {}'.format(sys.exc_info()[-1].tb_lineno), type(notexist2).__name__, notexist2)\n",
    "                    #print(str(notexist2))\n",
    "                    \n",
    "                    continue\n",
    "                    \n",
    "                # find answer dates\n",
    "                answer_date = part_soup.find(\"a\", string=lambda string: string and (\"Answered\" in string or \"Updated\" in string))#(\"a\", {\"class\": \"answer_permalink\"})\n",
    "                try:\n",
    "                    date = answer_date.text\n",
    "                    if (\"Updated\" in date):\n",
    "                        date= date[8:]\n",
    "                    else:\n",
    "                        date= date[9:]\n",
    "                    date=dateparser.parse(date).strftime(\"%Y-%m-%d\")\n",
    "                except: # when updated or answered in the same week (ex: Updated Sat)\n",
    "                    date=dateparser.parse(\"7 days ago\").strftime(\"%Y-%m-%d\")\n",
    "                #print(\"Posted: \" + date)\n",
    "                \n",
    "                # find answers text\n",
    "                answer_text = part_soup.find(\"div\", {\"class\": \"q-relative spacing_log_answer_content puppeteer_test_answer_content\"})\n",
    "                #print(\"Answer: \", answer_text.text)\n",
    "                answer_text = answer_text.text                 \n",
    "                \n",
    "                #write answer elements to file\n",
    "                s =  str(question_id.rstrip()) +'\\t' + str(date) + \"\\t\"+ user_id + \"\\t\"+ str(questions_topics_text) + \"\\t\" +\tstr(answer_text.rstrip())  + \"\\n\"\n",
    "                #print(\"wrting down the answer...\")\n",
    "                file_answers.write(s)\n",
    "                #print(' ')\n",
    "                               \n",
    "            except Exception as e1: # Most times because user is anonymous ,  continue without saving anything\n",
    "                #print('---------------There is an Exception-----------')\n",
    "                #print('Error on line {}'.format(sys.exc_info()[-1].tb_lineno), type(e1).__name__, e1)\n",
    "                #print(str(e1))\n",
    "                o=1\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling the answer function with vaccine controversial quora questions:\n",
    "\n",
    "https://www.quora.com/Are-you-planning-on-getting-the-vaccine-for-the-coronavirus-COVID-19-when-it-comes-out\n",
    "https://www.quora.com/How-safe-are-the-different-COVID-19-coronavirus-vaccinations\n",
    "https://www.quora.com/What-are-the-reasons-not-to-take-the-COVID-19-vaccine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-98-fb38260dca05>:11: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=chrome_options, executable_path=r'chromedriver.exe')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the answers crawling...\n",
      "--------------------------------------------------\n",
      "processing question number  : 1\n",
      "https://www.quora.com/What-are-the-reasons-not-to-take-the-COVID-19-vaccine\n",
      "Question have : 50 Answers\n",
      "scrolling down to get all answers...\n",
      "opened a total of 20 question boxes\n",
      "---------------There is an Exception-----------\n",
      "Error on line 131 AttributeError 'NoneType' object has no attribute 'text'\n",
      "'NoneType' object has no attribute 'text'\n",
      "---------------There is an Exception-----------\n",
      "Error on line 136 UnicodeEncodeError 'charmap' codec can't encode character '\\u202a' in position 419: character maps to <undefined>\n",
      "'charmap' codec can't encode character '\\u202a' in position 419: character maps to <undefined>\n",
      "--------------------------------------------------\n",
      "Crawling completed, answers have been saved to  :   C:\\Users\\johan\\Desktop\\scraping_project\n"
     ]
    }
   ],
   "source": [
    "answers([\"https://www.quora.com/What-are-the-reasons-not-to-take-the-COVID-19-vaccine\",], r\"C:\\Users\\johan\\Desktop\\scraping_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-95-d6c06ca05ae2>:11: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=chrome_options, executable_path=r'chromedriver.exe')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the answers crawling...\n",
      "--------------------------------------------------\n",
      "processing question number  : 1\n",
      "https://www.quora.com/How-safe-are-the-different-COVID-19-coronavirus-vaccinations\n",
      "Question have : 298 Answers\n",
      "scrolling down to get all answers...\n",
      "opened a total of 117 question boxes\n",
      "author extract pb\n",
      "Error on line 105 TypeError 'NoneType' object is not subscriptable\n",
      "'NoneType' object is not subscriptable\n",
      "---------------There is an Exception-----------\n",
      "Error on line 134 UnicodeEncodeError 'charmap' codec can't encode character '\\u2264' in position 1197: character maps to <undefined>\n",
      "'charmap' codec can't encode character '\\u2264' in position 1197: character maps to <undefined>\n",
      "---------------There is an Exception-----------\n",
      "Error on line 134 UnicodeEncodeError 'charmap' codec can't encode character '\\U0001f914' in position 622: character maps to <undefined>\n",
      "'charmap' codec can't encode character '\\U0001f914' in position 622: character maps to <undefined>\n",
      "---------------There is an Exception-----------\n",
      "Error on line 134 UnicodeEncodeError 'charmap' codec can't encode characters in position 308-311: character maps to <undefined>\n",
      "'charmap' codec can't encode characters in position 308-311: character maps to <undefined>\n",
      "author extract pb\n",
      "Error on line 105 TypeError 'NoneType' object is not subscriptable\n",
      "'NoneType' object is not subscriptable\n",
      "author extract pb\n",
      "Error on line 105 TypeError 'NoneType' object is not subscriptable\n",
      "'NoneType' object is not subscriptable\n",
      "---------------There is an Exception-----------\n",
      "Error on line 134 UnicodeEncodeError 'charmap' codec can't encode character '\\U0001f602' in position 263: character maps to <undefined>\n",
      "'charmap' codec can't encode character '\\U0001f602' in position 263: character maps to <undefined>\n",
      "---------------There is an Exception-----------\n",
      "Error on line 134 UnicodeEncodeError 'charmap' codec can't encode character '\\u2265' in position 541: character maps to <undefined>\n",
      "'charmap' codec can't encode character '\\u2265' in position 541: character maps to <undefined>\n",
      "author extract pb\n",
      "Error on line 105 TypeError 'NoneType' object is not subscriptable\n",
      "'NoneType' object is not subscriptable\n",
      "---------------There is an Exception-----------\n",
      "Error on line 134 UnicodeEncodeError 'charmap' codec can't encode character '\\u0155' in position 277: character maps to <undefined>\n",
      "'charmap' codec can't encode character '\\u0155' in position 277: character maps to <undefined>\n",
      "---------------There is an Exception-----------\n",
      "Error on line 134 UnicodeEncodeError 'charmap' codec can't encode character '\\U0001f629' in position 162: character maps to <undefined>\n",
      "'charmap' codec can't encode character '\\U0001f629' in position 162: character maps to <undefined>\n",
      "---------------There is an Exception-----------\n",
      "Error on line 134 UnicodeEncodeError 'charmap' codec can't encode character '\\U0001f614' in position 279: character maps to <undefined>\n",
      "'charmap' codec can't encode character '\\U0001f614' in position 279: character maps to <undefined>\n",
      "---------------There is an Exception-----------\n",
      "Error on line 134 UnicodeEncodeError 'charmap' codec can't encode character '\\U0001f923' in position 93: character maps to <undefined>\n",
      "'charmap' codec can't encode character '\\U0001f923' in position 93: character maps to <undefined>\n",
      "---------------There is an Exception-----------\n",
      "Error on line 134 UnicodeEncodeError 'charmap' codec can't encode characters in position 10322-10323: character maps to <undefined>\n",
      "'charmap' codec can't encode characters in position 10322-10323: character maps to <undefined>\n",
      "author extract pb\n",
      "Error on line 105 TypeError 'NoneType' object is not subscriptable\n",
      "'NoneType' object is not subscriptable\n",
      "author extract pb\n",
      "Error on line 105 TypeError 'NoneType' object is not subscriptable\n",
      "'NoneType' object is not subscriptable\n",
      "--------------------------------------------------\n",
      "Crawling completed, answers have been saved to  :   C:\\Users\\johan\\Desktop\\scraping_project\n"
     ]
    }
   ],
   "source": [
    "answers([\"https://www.quora.com/How-safe-are-the-different-COVID-19-coronavirus-vaccinations\",], r\"C:\\Users\\johan\\Desktop\\scraping_project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a pandas dataframe with our scraped data (change to correct path):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 71: expected 5 fields, saw 6\\n'\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\johan\\Desktop\\scraping_project\\answers.txt\", delimiter = \"\t\",\n",
    "                 encoding='cp1252', error_bad_lines=False, header = None)\n",
    "df.columns = ['Question', 'Date', 'User', 'b', 'Answer']\n",
    "df = df.drop(['b'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How-safe-are-the-different-COVID-19-coronaviru...</td>\n",
       "      <td>2021-01-26</td>\n",
       "      <td>Rachel-Anderson-166</td>\n",
       "      <td>ORIGINAL QUESTION: Is the Covid vaccine proved...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How-safe-are-the-different-COVID-19-coronaviru...</td>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>Bruce-Spielbauer</td>\n",
       "      <td>In the US, only one vaccine has been approved ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How-safe-are-the-different-COVID-19-coronaviru...</td>\n",
       "      <td>2021-04-19</td>\n",
       "      <td>Mobisoft-Infotech-1</td>\n",
       "      <td>Most of the countries are creating vaccines to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How-safe-are-the-different-COVID-19-coronaviru...</td>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>Frank-Hollis</td>\n",
       "      <td>Yes. My mother is being vaccinated tomorrow. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How-safe-are-the-different-COVID-19-coronaviru...</td>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>C-S-Friedman</td>\n",
       "      <td>Nope. Feel free to step on out of line and han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>How-safe-are-the-different-COVID-19-coronaviru...</td>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>Warren-Sponholtz</td>\n",
       "      <td>People need to have fully informed consent whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>How-safe-are-the-different-COVID-19-coronaviru...</td>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>Elena-Watson-28</td>\n",
       "      <td>Covid-19 Vaccine:COVID-19 vaccine is finally h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>How-safe-are-the-different-COVID-19-coronaviru...</td>\n",
       "      <td>2020-07-19</td>\n",
       "      <td>Bernard-Peter-Gore</td>\n",
       "      <td>We don't “believe, in vaccines, we test them. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>How-safe-are-the-different-COVID-19-coronaviru...</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>Patricia-Yeargin-1</td>\n",
       "      <td>There is not yet an approved vaccine, so this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>How-safe-are-the-different-COVID-19-coronaviru...</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>Richard-Cavner</td>\n",
       "      <td>It has roughly the same instance rate of adver...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>452 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Question        Date  \\\n",
       "0    How-safe-are-the-different-COVID-19-coronaviru...  2021-01-26   \n",
       "1    How-safe-are-the-different-COVID-19-coronaviru...  2021-01-18   \n",
       "2    How-safe-are-the-different-COVID-19-coronaviru...  2021-04-19   \n",
       "3    How-safe-are-the-different-COVID-19-coronaviru...  2021-01-18   \n",
       "4    How-safe-are-the-different-COVID-19-coronaviru...  2020-12-18   \n",
       "..                                                 ...         ...   \n",
       "453  How-safe-are-the-different-COVID-19-coronaviru...  2021-02-15   \n",
       "454  How-safe-are-the-different-COVID-19-coronaviru...  2021-02-12   \n",
       "455  How-safe-are-the-different-COVID-19-coronaviru...  2020-07-19   \n",
       "456  How-safe-are-the-different-COVID-19-coronaviru...  2020-08-19   \n",
       "457  How-safe-are-the-different-COVID-19-coronaviru...  2020-11-19   \n",
       "\n",
       "                    User                                             Answer  \n",
       "0    Rachel-Anderson-166  ORIGINAL QUESTION: Is the Covid vaccine proved...  \n",
       "1       Bruce-Spielbauer  In the US, only one vaccine has been approved ...  \n",
       "2    Mobisoft-Infotech-1  Most of the countries are creating vaccines to...  \n",
       "3           Frank-Hollis  Yes. My mother is being vaccinated tomorrow. I...  \n",
       "4           C-S-Friedman  Nope. Feel free to step on out of line and han...  \n",
       "..                   ...                                                ...  \n",
       "453     Warren-Sponholtz  People need to have fully informed consent whe...  \n",
       "454      Elena-Watson-28  Covid-19 Vaccine:COVID-19 vaccine is finally h...  \n",
       "455   Bernard-Peter-Gore  We don't “believe, in vaccines, we test them. ...  \n",
       "456   Patricia-Yeargin-1  There is not yet an approved vaccine, so this ...  \n",
       "457       Richard-Cavner  It has roughly the same instance rate of adver...  \n",
       "\n",
       "[452 rows x 4 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Answer'].isnull().sum()\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f895f3828335fe46f73ce365c88adfdf701549b1031659c6fc3c92d79d692c8b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
